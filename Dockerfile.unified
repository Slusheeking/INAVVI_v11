# Pull the latest TensorFlow container with CUDA 12.4 support for NVIDIA GH200 Grace Hopper Superchips
FROM nvcr.io/nvidia/tensorflow:24.02-tf2-py3

# Install required system packages including Redis and Prometheus
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    wget \
    python3-dev \
    redis-server \
    prometheus \
    prometheus-node-exporter \
    supervisor \
    curl \
    libpq-dev \
    postgresql-client \
    git \
    vim \
    tmux \
    htop \
    cmake \
    ninja-build \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# Install Redis Exporter
RUN wget https://github.com/oliver006/redis_exporter/releases/download/v1.54.0/redis_exporter-v1.54.0.linux-arm64.tar.gz && \
    tar xzf redis_exporter-v1.54.0.linux-arm64.tar.gz && \
    mv redis_exporter-v1.54.0.linux-arm64/redis_exporter /usr/local/bin/ && \
    rm -rf redis_exporter-v1.54.0.linux-arm64*

# Set environment variables for CUDA 12.4 and GH200 optimization
ENV LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:${LD_LIBRARY_PATH}
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}

# Enhanced TF32 acceleration and GPU optimization for GH200 Grace Hopper Superchips
ENV NVIDIA_TF32_OVERRIDE=1
ENV CUDA_DEVICE_MAX_CONNECTIONS=32
ENV TF_FORCE_UNIFIED_MEMORY=1
ENV TF_ENABLE_NUMA_AWARE_ALLOCATORS=1
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility,video,graphics
ENV TF_FORCE_GPU_ALLOW_GROWTH=true
ENV TF_XLA_FLAGS="--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit --tf_xla_enable_lazy_compilation=false"
ENV TF_CUDA_HOST_MEM_LIMIT_IN_MB=32000
ENV TF_GPU_THREAD_MODE=gpu_private
ENV TF_GPU_THREAD_COUNT=8
ENV TF_GPU_ALLOCATOR=cuda_malloc_async
ENV TF_USE_CUDA_GRAPHS=1
ENV XLA_FLAGS="--xla_gpu_cuda_data_dir=/usr/local/cuda --xla_gpu_enable_fast_min_max=true"
ENV TF_CUDNN_USE_AUTOTUNE=1
ENV TF_LAYOUT_OPTIMIZER_DISABLE=1
ENV TF_ENABLE_ONEDNN_OPTS=0
ENV CUDA_AUTO_BOOST=1
ENV NCCL_IB_DISABLE=0
ENV NCCL_P2P_LEVEL=NVL
ENV NCCL_DEBUG=INFO
ENV GOMP_CPU_AFFINITY="0-31"
ENV MALLOC_TRIM_THRESHOLD_=0
ENV MALLOC_MMAP_THRESHOLD_=131072

# TensorRT optimization settings
ENV TF_TRT_ALLOW_ENGINE_NATIVE_SEGMENT=true
ENV TF_TRT_ALLOW_CUSTOM_OPS=true
ENV TF_TRT_USE_IMPLICIT_BATCH=false
ENV TF_TRT_ALLOW_DYNAMIC_SHAPES=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_REDUCTION=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_CONVERSION=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_WEIGHTS=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_VARIABLES=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_CONSTANTS=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_ACTIVATION=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_ACCUMULATION=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_REDUCTION_AGGREGATION=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_REDUCTION_INITIALIZATION=true
ENV TF_TRT_ALLOW_REDUCED_PRECISION_REDUCTION_ACCUMULATION=true

# CuPy optimization settings
ENV CUPY_CACHE_DIR=/app/data/cache/cupy
ENV CUPY_CACHE_SAVE_CUDA_SOURCE=1
ENV CUPY_ACCELERATORS=cub,cutensor
ENV CUPY_TF32=1
ENV CUPY_CUDA_COMPILE_WITH_DEBUG=0

# Install additional Python packages with ARM64 compatibility
RUN pip install --upgrade pip && \
    # Install core dependencies first
    pip install --no-cache-dir \
    pandas \
    numpy \
    requests \
    redis \
    urllib3 \
    aiohttp \
    websockets \
    prometheus_client && \
    # Install ML packages with specific versions
    pip install --no-cache-dir \
    scikit-learn==1.3.2 \
    pyarrow==14.0.1 \
    numba>=0.57.0 && \
    # Install visualization and notebook packages
    pip install --no-cache-dir \
    matplotlib \
    jupyterlab \
    ipywidgets && \
    # Install GPU-related packages with specific CUDA version
    # Use a more robust approach to detect CUDA version
    CUDA_VERSION=$(nvcc --version | grep -o "release [0-9]\+\.[0-9]\+" | awk '{print $2}' | cut -d. -f1-2) && \
    echo "Detected CUDA version: ${CUDA_VERSION}" && \
    # For CUDA 12.x series, use the simplified package name format with optimized build
    pip install --no-cache-dir \
    cupy-cuda12x \
    pycuda && \
    # Create CuPy cache directory
    mkdir -p /app/data/cache/cupy && \
    chmod 777 /app/data/cache/cupy

# Verify TensorRT is already installed in the NVIDIA container
RUN python3 -c "import tensorrt; print(f'TensorRT version: {tensorrt.__version__}')" || \
    echo "TensorRT not found, will be installed with other packages"

# Remove any conflicting TensorFlow packages first
# Note: We're not reinstalling tensorflow-addons as it's causing build issues
RUN pip uninstall -y tensorflow-text tensorflow-datasets tensorflow-addons || true

# Install selected TensorFlow add-on packages (avoiding conflicting dependencies)
# Skip tensorflow-addons as it's causing build issues
RUN pip install --no-cache-dir \
    tensorflow-probability \
    tensorflow-datasets \
    tensorflow-hub \
    tensorflow-model-optimization \
    tensorflow-io

# Use the pre-installed XGBoost from the NVIDIA container
RUN python3 -c "import xgboost; print(f'XGBoost version: {xgboost.__version__}'); print('GPU support available' if xgboost.config_context()['gpu_id'] is not None else 'No GPU support')" || \
    pip install --no-cache-dir xgboost

# Install trading-specific packages
RUN pip install --no-cache-dir \
    polygon-api-client \
    nvidia-ml-py3 \
    alpaca-trade-api \
    packaging \
    pytz \
    schedule \
    pymongo \
    sqlalchemy \
    psycopg2-binary \
    statsmodels \
    scipy \
    lightgbm \
    optuna \
    pytest \
    asyncpg \
    boto3 \
    joblib \
    retrying \
    # Install additional GPU utilities
    pynvml \
    nvitop \
    gputil \
    py3nvml \
    # Install frontend-related packages
    flask \
    flask-cors \
    flask-socketio \
    eventlet \
    gevent \
    redis-py-cluster \
    flask-redis \
    flask-session

# Create working directories
WORKDIR /app
RUN mkdir -p /app/models /app/data /app/logs /app/config

# Create directories and set permissions for Redis and other services
RUN mkdir -p /var/log/supervisor && \
    mkdir -p /var/log/redis && \
    mkdir -p /var/log/prometheus && \
    mkdir -p /var/run/redis && \
    mkdir -p /data && \
    mkdir -p /var/lib/redis && \
    mkdir -p /app/data/redis && \
    mkdir -p /app/data/market_data && \
    mkdir -p /app/data/processed && \
    mkdir -p /app/data/signals && \
    mkdir -p /app/models/signal_detection && \
    mkdir -p /app/models/price_prediction && \
    mkdir -p /app/models/risk_assessment && \
    mkdir -p /app/logs/trading && \
    mkdir -p /app/logs/ml && \
    mkdir -p /app/logs/monitoring && \
    mkdir -p /app/logs/frontend && \
    mkdir -p /app/logs/events && \
    touch /var/log/redis/redis-server.err.log && \
    touch /var/log/redis/redis-server.out.log && \
    touch /var/log/prometheus.err.log && \
    touch /var/log/prometheus.out.log && \
    touch /var/log/redis_exporter.err.log && \
    touch /var/log/redis_exporter.out.log && \
    touch /var/log/jupyter.err.log && \
    touch /var/log/jupyter.out.log && \
    touch /var/log/trading_system.err.log && \
    touch /var/log/trading_system.out.log && \
    touch /var/log/peak_monitor.err.log && \
    touch /var/log/peak_monitor.out.log && \
    touch /var/log/model_training.err.log && \
    touch /var/log/model_training.out.log && \
    touch /var/log/data_pipeline.err.log && \
    touch /var/log/data_pipeline.out.log && \
    touch /var/log/stock_selection.err.log && \
    touch /var/log/stock_selection.out.log && \
    touch /var/log/frontend.err.log && \
    touch /var/log/frontend.out.log && \
    touch /var/log/redis_event_listener.err.log && \
    touch /var/log/redis_event_listener.out.log && \
    chmod -R 777 /var/log/redis && \
    chmod -R 777 /var/run/redis && \
    chmod -R 777 /data && \
    chmod -R 777 /var/lib/redis && \
    chmod -R 777 /app/data/redis

# Create Redis configuration file
RUN echo '# Redis configuration for trading system\n\
    port 6380\n\
    bind 0.0.0.0\n\
    daemonize no\n\
    supervised systemd\n\
    loglevel notice\n\
    logfile /var/log/redis/redis-server.log\n\
    \n\
    # Security\n\
    requirepass trading_system_2025\n\
    user default on +@all ~* >trading_system_2025\n\
    \n\
    # Memory management\n\
    maxmemory 4gb\n\
    maxmemory-policy allkeys-lru\n\
    stop-writes-on-bgsave-error no\n\
    \n\
    # Persistence\n\
    dir /data\n\
    dbfilename dump.rdb\n\
    save 900 1\n\
    save 300 10\n\
    save 60 10000\n\
    rdbcompression yes\n\
    rdbchecksum yes\n\
    \n\
    # Performance tuning\n\
    tcp-backlog 511\n\
    tcp-keepalive 300\n\
    timeout 0\n\
    databases 16\n\
    ' > /etc/redis/redis.conf

# Create Prometheus configuration file
RUN echo 'global:\n\
    scrape_interval: 15s\n\
    evaluation_interval: 15s\n\
    \n\
    scrape_configs:\n\
    - job_name: "prometheus"\n\
    static_configs:\n\
    - targets: ["localhost:9090"]\n\
    \n\
    - job_name: "redis"\n\
    static_configs:\n\
    - targets: ["localhost:9121"]\n\
    \n\
    - job_name: "node"\n\
    static_configs:\n\
    - targets: ["localhost:9100"]\n\
    ' > /etc/prometheus/prometheus.yml

# Configure supervisord for service management
RUN echo '[supervisord]\n\
    nodaemon=true\n\
    logfile=/var/log/supervisor/supervisord.log\n\
    logfile_maxbytes=50MB\n\
    logfile_backups=5\n\
    loglevel=info\n\
    \n\
    [program:redis]\n\
    command=/usr/bin/redis-server /etc/redis/redis.conf\n\
    autostart=true\n\
    autorestart=true\n\
    stderr_logfile=/var/log/redis/redis-server.err.log\n\
    stdout_logfile=/var/log/redis/redis-server.out.log\n\
    priority=10\n\
    startsecs=5\n\
    startretries=3\n\
    \n\
    [program:prometheus]\n\
    command=/usr/bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus\n\
    autostart=true\n\
    autorestart=true\n\
    stderr_logfile=/var/log/prometheus.err.log\n\
    stdout_logfile=/var/log/prometheus.out.log\n\
    priority=20\n\
    \n\
    [program:redis_exporter]\n\
    command=/usr/local/bin/redis_exporter\n\
    autostart=true\n\
    autorestart=true\n\
    stderr_logfile=/var/log/redis_exporter.err.log\n\
    stdout_logfile=/var/log/redis_exporter.out.log\n\
    priority=30\n\
    \n\
    [program:jupyter]\n\
    command=jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=""\n\
    autostart=true\n\
    autorestart=true\n\
    stderr_logfile=/var/log/jupyter.err.log\n\
    stdout_logfile=/var/log/jupyter.out.log\n\
    priority=40\n\
    \n\
    [program:trading_system]\n\
    command=python3 /app/project/scripts/start_system.py --health-check-interval=300\n\
    directory=/app/project\n\
    autostart=true\n\
    autorestart=true\n\
    stderr_logfile=/var/log/trading_system.err.log\n\
    stdout_logfile=/var/log/trading_system.out.log\n\
    priority=50\n\
    environment=PYTHONPATH="/app/project"\n\
    stopwaitsecs=60\n\
    stopsignal=TERM\n\
    stopasgroup=true\n\
    killasgroup=true\n\
    \n\
    [program:frontend]\n\
    command=python -m flask run --host=0.0.0.0 --port=5000 --with-threads\n\
    directory=/app/project\n\
    autostart=true\n\
    autorestart=true\n\
    stderr_logfile=/var/log/frontend.err.log\n\
    stdout_logfile=/var/log/frontend.out.log\n\
    priority=60\n\
    environment=PYTHONPATH="/app/project",FLASK_APP="/app/project/frontend/app.py",FLASK_ENV="development",FLASK_DEBUG="1",FLASK_RUN_PORT="5000",FLASK_RUN_EXTRA_FILES="/app/project/frontend/templates/*",FRONTEND_WEBSOCKET_ENABLED="true",FRONTEND_REALTIME_UPDATES="true"\n\
    stopwaitsecs=30\n\
    stopsignal=TERM\n\
    stopasgroup=true\n\
    killasgroup=true\n\
    \n\
    [program:redis_event_listener]\n\
    command=python -m frontend.event_listener\n\
    directory=/app/project\n\
    autostart=true\n\
    autorestart=true\n\
    stderr_logfile=/var/log/redis_event_listener.err.log\n\
    stdout_logfile=/var/log/redis_event_listener.out.log\n\
    priority=65\n\
    environment=PYTHONPATH="/app/project",REDIS_PUBSUB_THREADS="4",REDIS_NOTIFY_KEYSPACE_EVENTS="Kxe"\n\
    stopwaitsecs=20\n\
    stopsignal=TERM\n\
    stopasgroup=true\n\
    killasgroup=true\n\
    ' > /etc/supervisor/conf.d/services.conf

# Create sysctl file for Redis
RUN echo "vm.overcommit_memory = 1" >> /etc/sysctl.conf

# Create startup script
RUN echo '#!/bin/bash\n\
    set -e\n\
    \n\
    echo "Starting up trading system container with integrated fixes..."\n\
    \n\
    # Ensure hosts file is correct\n\
    echo "127.0.0.1 localhost" > /etc/hosts\n\
    \n\
    # Apply Redis overcommit_memory setting\n\
    echo "Applying Redis overcommit_memory setting..."\n\
    sysctl vm.overcommit_memory=1 || echo "Warning: Could not set vm.overcommit_memory=1"\n\
    \n\
    # Verify Redis data directories exist and have proper permissions\n\
    echo "Verifying Redis directories and permissions..."\n\
    mkdir -p /data /var/lib/redis /app/data/redis\n\
    chmod -R 777 /data /var/lib/redis /app/data/redis\n\
    \n\
    # Create required project directories\n\
    mkdir -p /app/project/frontend/templates /app/project/frontend/sessions\n\
    \n\
    # Start Redis server explicitly first\n\
    echo "Starting Redis server..."\n\
    redis-server /etc/redis/redis.conf &\n\
    REDIS_PID=$!\n\
    \n\
    # Give Redis time to start\n\
    echo "Waiting for Redis to initialize..."\n\
    sleep 5\n\
    \n\
    # Test Redis connection\n\
    echo "Testing Redis connection..."\n\
    if redis-cli -p 6380 -a trading_system_2025 ping | grep -q PONG; then\n\
    echo "Redis is running correctly."\n\
    else\n\
    echo "Redis failed to start properly. Trying alternative method..."\n\
    kill $REDIS_PID || true\n\
    sleep 2\n\
    redis-server --port 6380 --requirepass trading_system_2025 --daemonize no &\n\
    REDIS_PID=$!\n\
    sleep 3\n\
    \n\
    # Check again\n\
    if redis-cli -p 6380 -a trading_system_2025 ping | grep -q PONG; then\n\
    echo "Redis is now running correctly."\n\
    else\n\
    echo "Warning: Redis is still not responding. Will try to continue..."\n\
    fi\n\
    fi\n\
    \n\
    # Configure TensorFlow GPU\n\
    echo "Configuring TensorFlow GPU..."\n\
    python3 -c "\n\
    import os\n\
    import tensorflow as tf\n\
    print(\"TensorFlow version:\", tf.__version__)\n\
    os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n\
    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\
    os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\n\
    gpus = tf.config.list_physical_devices(\"GPU\")\n\
    if gpus:\n\
    for gpu in gpus:\n\
    try:\n\
    tf.config.experimental.set_memory_growth(gpu, True)\n\
    print(f\"Memory growth set for GPU: {gpu}\")\n\
    except Exception as e:\n\
    print(f\"Error setting memory growth: {e}\")\n\
    print(f\"GPU configuration applied. Found {len(gpus)} GPU(s).\")\n\
    else:\n\
    print(\"No GPUs found to configure.\")\n\
    "\n\
    \n\
    # Optional: Create a basic default index.html template if none exists yet\n\
    if [ ! -f /app/project/frontend/templates/index.html ]; then\n\
    echo "Creating default index.html template..."\n\
    mkdir -p /app/project/frontend/templates\n\
    cat > /app/project/frontend/templates/index.html << "ENDHTML"\n\
    <!DOCTYPE html>\n\
    <html>\n\
    <head>\n\
    <title>Trading System Dashboard</title>\n\
    <meta charset="UTF-8">\n\
    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n\
    <style>\n\
    body { font-family: Arial, sans-serif; margin: 0; padding: 20px; background-color: #f5f5f5; }\n\
    .container { max-width: 1200px; margin: 0 auto; background-color: white; padding: 20px; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }\n\
    h1 { color: #333; }\n\
    .card { background-color: white; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); padding: 15px; margin-bottom: 20px; }\n\
    .card-title { font-size: 18px; font-weight: bold; margin-bottom: 10px; }\n\
    .grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); gap: 20px; }\n\
    </style>\n\
    </head>\n\
    <body>\n\
    <div class="container">\n\
    <h1>Trading System Dashboard</h1>\n\
    <p>System is running. This is a basic frontend template.</p>\n\
    \n\
    <div class="grid">\n\
    <div class="card">\n\
    <div class="card-title">System Status</div>\n\
    <div>Status: Running</div>\n\
    </div>\n\
    \n\
    <div class="card">\n\
    <div class="card-title">GPU Status</div>\n\
    <div>NVIDIA GH200 480GB</div>\n\
    </div>\n\
    \n\
    <div class="card">\n\
    <div class="card-title">Redis Status</div>\n\
    <div>Connected on port 6380</div>\n\
    </div>\n\
    \n\
    <div class="card">\n\
    <div class="card-title">TensorFlow Status</div>\n\
    <div>Version: 2.15.0</div>\n\
    </div>\n\
    </div>\n\
    </div>\n\
    </body>\n\
    </html>\n\
    ENDHTML\n\
    fi\n\
    \n\
    # Create shutdown script\n\
    echo "Creating shutdown script..."\n\
    cat > /app/shutdown.sh << "ENDSHUTDOWN"\n\
    #!/bin/bash\n\
    # Trading System Container Shutdown Script\n\
    \n\
    echo "Initiating graceful shutdown of trading system container..."\n\
    \n\
    # Stop the trading system components first\n\
    if [ -f /app/project/scripts/stop_system.py ]; then\n\
    echo "Stopping trading system components..."\n\
    cd /app/project\n\
    python3 /app/project/scripts/stop_system.py --force\n\
    else\n\
    echo "Warning: stop_system.py not found, skipping component shutdown"\n\
    fi\n\
    \n\
    # Stop Redis if running\n\
    if pgrep redis-server > /dev/null; then\n\
    echo "Stopping Redis server..."\n\
    redis-cli -p 6380 -a trading_system_2025 shutdown || redis-cli shutdown\n\
    sleep 2\n\
    fi\n\
    \n\
    # Stop Prometheus if running\n\
    if pgrep prometheus > /dev/null; then\n\
    echo "Stopping Prometheus..."\n\
    pkill -SIGTERM prometheus\n\
    sleep 2\n\
    fi\n\
    \n\
    # Stop Redis exporter if running\n\
    if pgrep redis_exporter > /dev/null; then\n\
    echo "Stopping Redis exporter..."\n\
    pkill -SIGTERM redis_exporter\n\
    sleep 1\n\
    fi\n\
    \n\
    # Stop Flask if running\n\
    if pgrep -f "python -m flask" > /dev/null; then\n\
    echo "Stopping Flask frontend..."\n\
    pkill -SIGTERM -f "python -m flask"\n\
    sleep 1\n\
    fi\n\
    \n\
    # Stop event listener if running\n\
    if pgrep -f "python -m frontend.event_listener" > /dev/null; then\n\
    echo "Stopping Redis event listener..."\n\
    pkill -SIGTERM -f "python -m frontend.event_listener"\n\
    sleep 1\n\
    fi\n\
    \n\
    # Stop supervisord last\n\
    if pgrep supervisord > /dev/null; then\n\
    echo "Stopping supervisord..."\n\
    supervisorctl shutdown\n\
    sleep 2\n\
    fi\n\
    \n\
    echo "Shutdown complete."\n\
    ENDSHUTDOWN\n\
    chmod +x /app/shutdown.sh\n\
    \n\
    echo "All initialization completed successfully."\n\
    echo "Starting services with supervisord..."\n\
    exec /usr/bin/supervisord -c /etc/supervisor/conf.d/services.conf\n\
    ' > /app/startup.sh && chmod +x /app/startup.sh

# Expose ports
EXPOSE 8888 6380 9090 9121 5000 8000

# Copy our configuration files
COPY prometheus/prometheus.yml /etc/prometheus/prometheus.yml
COPY redis/redis.conf /etc/redis/redis.conf
COPY services.conf /etc/supervisor/conf.d/services.conf

# Copy our startup script, enhanced unified GPU test, and portfolio updater
COPY startup.sh /app/startup.sh
COPY unified_gpu_test.py /app/project/unified_gpu_test.py
COPY update_portfolio.py /app/project/update_portfolio.py

# Make scripts executable
RUN chmod +x /app/startup.sh

# Start all services using the startup script
CMD ["/bin/bash", "/app/startup.sh"]